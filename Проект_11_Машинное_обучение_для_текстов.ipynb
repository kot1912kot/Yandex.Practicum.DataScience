{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод:\" data-toc-modified-id=\"Вывод:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод:</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li><li><span><a href=\"#-Комментарий-ревьюера\" data-toc-modified-id=\"-Комментарий-ревьюера-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span> Комментарий ревьюера</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загрузим данные\n",
    "df = pd.read_csv(\"/datasets/toxic_comments.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#посмотрим информацию о ДФ\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa1180df210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#посмотрим на количество токсичных и нет файлов\n",
    "sns.countplot(x=\"toxic\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим что нетоксичных слов во много раз больше чем токсичных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                         punctuation  \n",
       "0  Explanation\\nWhy the edits made under my usern...  \n",
       "1  Daww He matches this background colour Im seem...  \n",
       "2  Hey man Im really not trying to edit war Its j...  \n",
       "3  \\nMore\\nI cant make any real suggestions on im...  \n",
       "4  You sir are my hero Any chance you remember wh...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#уберем знаки препинания\n",
    "def no_punct(text):\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    text = re.sub(\"[0-9]+\", \"\", text)\n",
    "    return text\n",
    "df[\"punctuation\"] = df[\"text\"].apply(lambda x: no_punct(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "      <td>[, more, i, cant, make, any, real, suggestions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  Daww He matches this background colour Im seem...   \n",
       "2  Hey man Im really not trying to edit war Its j...   \n",
       "3  \\nMore\\nI cant make any real suggestions on im...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                            tokenize  \n",
       "0  [explanation, why, the, edits, made, under, my...  \n",
       "1  [daww, he, matches, this, background, colour, ...  \n",
       "2  [hey, man, im, really, not, trying, to, edit, ...  \n",
       "3  [, more, i, cant, make, any, real, suggestions...  \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проведем токенизацию\n",
    "def tokenization(text):\n",
    "    text = re.split(\"\\W+\", text)\n",
    "    return text\n",
    "df[\"tokenize\"] = df[\"punctuation\"].apply(lambda x: tokenization(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[daww, matches, background, colour, im, seemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "      <td>[hey, man, im, really, trying, edit, war, guy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "      <td>[, more, i, cant, make, any, real, suggestions...</td>\n",
       "      <td>[, cant, make, real, suggestions, improvement,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page, thats]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  Daww He matches this background colour Im seem...   \n",
       "2  Hey man Im really not trying to edit war Its j...   \n",
       "3  \\nMore\\nI cant make any real suggestions on im...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [daww, he, matches, this, background, colour, ...   \n",
       "2  [hey, man, im, really, not, trying, to, edit, ...   \n",
       "3  [, more, i, cant, make, any, real, suggestions...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                           stopwords  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [daww, matches, background, colour, im, seemin...  \n",
       "2  [hey, man, im, really, trying, edit, war, guy,...  \n",
       "3  [, cant, make, real, suggestions, improvement,...  \n",
       "4         [sir, hero, chance, remember, page, thats]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удалим стоп-слова\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def stop_words(text):\n",
    "    text = [i for i in text if i not in stopword]\n",
    "    return text\n",
    "df[\"stopwords\"] = df[\"tokenize\"].apply(lambda x: stop_words(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[daww, matches, background, colour, im, seemin...</td>\n",
       "      <td>[daww, match, background, colour, im, seemingl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "      <td>[hey, man, im, really, trying, edit, war, guy,...</td>\n",
       "      <td>[hey, man, im, really, trying, edit, war, guy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "      <td>[, more, i, cant, make, any, real, suggestions...</td>\n",
       "      <td>[, cant, make, real, suggestions, improvement,...</td>\n",
       "      <td>[, cant, make, real, suggestion, improvement, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page, thats]</td>\n",
       "      <td>[sir, hero, chance, remember, page, thats]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  Daww He matches this background colour Im seem...   \n",
       "2  Hey man Im really not trying to edit war Its j...   \n",
       "3  \\nMore\\nI cant make any real suggestions on im...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [daww, he, matches, this, background, colour, ...   \n",
       "2  [hey, man, im, really, not, trying, to, edit, ...   \n",
       "3  [, more, i, cant, make, any, real, suggestions...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  [explanation, edits, made, username, hardcore,...   \n",
       "1  [daww, matches, background, colour, im, seemin...   \n",
       "2  [hey, man, im, really, trying, edit, war, guy,...   \n",
       "3  [, cant, make, real, suggestions, improvement,...   \n",
       "4         [sir, hero, chance, remember, page, thats]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [daww, match, background, colour, im, seemingl...  \n",
       "2  [hey, man, im, really, trying, edit, war, guy,...  \n",
       "3  [, cant, make, real, suggestion, improvement, ...  \n",
       "4         [sir, hero, chance, remember, page, thats]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#лемитизация\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def limitization(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['lemmatized'] = df['stopwords'].apply(lambda x: limitization(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "> Мы загрузили наш ДФ, он состоит из 2 столбцов и 159571 строк. Видим что нетоксичных комментариев намного больше чем токсичных. Провели лемитизацию, токенизациб, удалил стоп-слова, убрали знаки препинания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#поледим наши данные на обучающую и тестовую выборки\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зададим наши модели и их параметры \n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    'LGBMClassifier': lgb.LGBMClassifier()     \n",
    "}\n",
    "params = {\n",
    "    'LogisticRegression':{\n",
    "          'class_weight':['balanced', None],\n",
    "          'C':[1,10,100]\n",
    "    },        \n",
    "    'LGBMClassifier': {\n",
    "        'boosting_type':['gbdt'],\n",
    "        'objective':['binary'],\n",
    "        'learning_rate':[0.02,0.05],\n",
    "        'num_iterations':[500],\n",
    "        'num_leaves':[50,75],\n",
    "        'feature_fraction':[0.64,0.8],\n",
    "        'bagging_fraction':[0.8,0.9],\n",
    "        'bagging_freq':[1,2]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выделим признаки и целевой признак\n",
    "features = [\"text\", \"punctuation\", \"tokenize\", \"stopwords\", \"lemmatized\"]\n",
    "\n",
    "for feature in features:\n",
    "    X_train = train[feature]\n",
    "    y_train = train[\"toxic\"]\n",
    "    X_test = test[feature]\n",
    "    y_test = test[\"toxic\"]\n",
    "    \n",
    "    train_corpus = X_train.astype(\"U\")\n",
    "    tfidf_train = count_tf_idf.fit_transform(train_corpus)\n",
    "    \n",
    "    corpus_test = X_test.astype('U')\n",
    "    tfidf_test = count_tf_idf.transform(corpus_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#напишем функцию для обучения моделей\n",
    "# def fit_predict(X_train, y_train, X_test, y_test):\n",
    "#         for name in models.keys():\n",
    "#             est = models[name]\n",
    "#             est_params = params[name]\n",
    "#             gscv = GridSearchCV(estimator=est, param_grid=est_params, cv=5, n_jobs=-1,verbose=0)\n",
    "#             gscv.fit(X_train, y_train)     \n",
    "#             predictions = gscv.predict(X_test)\n",
    "#             result_list.append({\n",
    "#             'model': name,\n",
    "#             'feature': feature,\n",
    "#             'f1_score': f1_score(y_test, predictions),\n",
    "#             'best_params': gscv.best_estimator_\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_list = []\n",
    "# fit_predict(tfidf_train, y_train, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_param_searth = {'class_weight':['balanced', None], 'C':[1,10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [1, 10, 100], 'class_weight': ['balanced', None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_gscv = GridSearchCV(estimator=lg_model, param_grid=lg_param_searth, cv=5, n_jobs=-1,verbose=0)\n",
    "lg_gscv.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model_best = LogisticRegression(C=10, class_weight=None, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.7865832859579306\n"
     ]
    }
   ],
   "source": [
    "lg_model_best.fit(tfidf_train, y_train)\n",
    "lg_predictions = lg_model_best.predict(tfidf_test)\n",
    "print(\"F1_score:\", f1_score(y_test, lg_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подобрали наилучшие параметры для модели Логистической регрессии и обучили модель. F1_score получился 0.78 что соответствует нашим условиям"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 555,
    "start_time": "2021-07-20T17:25:08.310Z"
   },
   {
    "duration": 614,
    "start_time": "2021-07-20T17:25:42.009Z"
   },
   {
    "duration": 25,
    "start_time": "2021-07-20T17:26:12.411Z"
   },
   {
    "duration": 552,
    "start_time": "2021-07-20T17:28:02.770Z"
   },
   {
    "duration": 142,
    "start_time": "2021-07-20T17:29:14.622Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-20T17:39:49.641Z"
   },
   {
    "duration": 1225,
    "start_time": "2021-07-20T17:42:07.219Z"
   },
   {
    "duration": 1094,
    "start_time": "2021-07-20T17:42:39.449Z"
   },
   {
    "duration": 352,
    "start_time": "2021-07-20T17:43:17.484Z"
   },
   {
    "duration": 5922,
    "start_time": "2021-07-20T17:43:22.649Z"
   },
   {
    "duration": 3707,
    "start_time": "2021-07-20T17:46:52.104Z"
   },
   {
    "duration": 4689,
    "start_time": "2021-07-20T17:47:23.072Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T17:48:33.501Z"
   },
   {
    "duration": 13815,
    "start_time": "2021-07-20T17:52:05.359Z"
   },
   {
    "duration": 19592,
    "start_time": "2021-07-20T17:55:50.505Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-20T18:03:04.687Z"
   },
   {
    "duration": 112,
    "start_time": "2021-07-20T18:03:45.217Z"
   },
   {
    "duration": 220,
    "start_time": "2021-07-20T18:04:35.689Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-20T18:04:54.486Z"
   },
   {
    "duration": 16,
    "start_time": "2021-07-20T18:05:35.788Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-20T18:08:44.882Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T18:16:00.486Z"
   },
   {
    "duration": 7838,
    "start_time": "2021-07-20T18:16:51.345Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T18:17:49.287Z"
   },
   {
    "duration": 1385,
    "start_time": "2021-07-20T18:22:40.191Z"
   },
   {
    "duration": 617,
    "start_time": "2021-07-20T18:22:41.578Z"
   },
   {
    "duration": 21,
    "start_time": "2021-07-20T18:22:42.197Z"
   },
   {
    "duration": 224,
    "start_time": "2021-07-20T18:22:42.219Z"
   },
   {
    "duration": 5729,
    "start_time": "2021-07-20T18:22:43.575Z"
   },
   {
    "duration": 3775,
    "start_time": "2021-07-20T18:22:49.306Z"
   },
   {
    "duration": 13639,
    "start_time": "2021-07-20T18:22:53.083Z"
   },
   {
    "duration": 19254,
    "start_time": "2021-07-20T18:23:06.724Z"
   },
   {
    "duration": 121,
    "start_time": "2021-07-20T18:23:42.803Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-20T18:23:43.281Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T18:23:44.236Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T18:23:45.782Z"
   },
   {
    "duration": 8212,
    "start_time": "2021-07-20T18:23:48.242Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T18:25:35.603Z"
   },
   {
    "duration": 744643,
    "start_time": "2021-07-20T18:25:36.122Z"
   },
   {
    "duration": 37270,
    "start_time": "2021-07-20T18:38:43.737Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-20T18:39:21.009Z"
   },
   {
    "duration": 180,
    "start_time": "2021-07-20T18:43:33.451Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T18:44:22.766Z"
   },
   {
    "duration": 191,
    "start_time": "2021-07-20T18:44:25.710Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-20T18:44:59.735Z"
   },
   {
    "duration": 177,
    "start_time": "2021-07-20T18:45:04.166Z"
   },
   {
    "duration": 7254,
    "start_time": "2021-07-20T18:46:09.994Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T18:47:19.744Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-20T18:47:19.750Z"
   },
   {
    "duration": 3704,
    "start_time": "2021-07-20T18:47:35.827Z"
   },
   {
    "duration": 690443,
    "start_time": "2021-07-20T18:48:03.138Z"
   },
   {
    "duration": 36804,
    "start_time": "2021-07-20T19:01:36.681Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T19:02:36.146Z"
   },
   {
    "duration": 1473,
    "start_time": "2021-07-20T19:22:23.302Z"
   },
   {
    "duration": 647,
    "start_time": "2021-07-20T19:22:24.777Z"
   },
   {
    "duration": 22,
    "start_time": "2021-07-20T19:22:25.426Z"
   },
   {
    "duration": 227,
    "start_time": "2021-07-20T19:22:25.450Z"
   },
   {
    "duration": 6062,
    "start_time": "2021-07-20T19:22:25.679Z"
   },
   {
    "duration": 3811,
    "start_time": "2021-07-20T19:22:31.743Z"
   },
   {
    "duration": 13609,
    "start_time": "2021-07-20T19:22:35.556Z"
   },
   {
    "duration": 19220,
    "start_time": "2021-07-20T19:22:49.167Z"
   },
   {
    "duration": 134,
    "start_time": "2021-07-20T19:23:08.389Z"
   },
   {
    "duration": 2,
    "start_time": "2021-07-20T19:23:08.525Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-20T19:23:08.529Z"
   },
   {
    "duration": 36594,
    "start_time": "2021-07-20T19:23:08.536Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-20T19:23:45.132Z"
   },
   {
    "duration": 2397,
    "start_time": "2021-07-21T04:36:45.787Z"
   },
   {
    "duration": 1394,
    "start_time": "2021-07-21T04:36:48.187Z"
   },
   {
    "duration": 34,
    "start_time": "2021-07-21T04:36:49.586Z"
   },
   {
    "duration": 347,
    "start_time": "2021-07-21T04:36:49.624Z"
   },
   {
    "duration": 11969,
    "start_time": "2021-07-21T04:36:49.974Z"
   },
   {
    "duration": 6320,
    "start_time": "2021-07-21T04:37:01.945Z"
   },
   {
    "duration": 26014,
    "start_time": "2021-07-21T04:37:08.267Z"
   },
   {
    "duration": 36297,
    "start_time": "2021-07-21T04:37:34.285Z"
   },
   {
    "duration": 164,
    "start_time": "2021-07-21T04:38:10.585Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-21T04:38:10.752Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-21T04:38:10.762Z"
   },
   {
    "duration": 60086,
    "start_time": "2021-07-21T04:38:10.771Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-21T04:39:10.863Z"
   },
   {
    "duration": 375,
    "start_time": "2021-07-21T15:39:10.098Z"
   },
   {
    "duration": 2047,
    "start_time": "2021-07-21T15:39:25.137Z"
   },
   {
    "duration": 826,
    "start_time": "2021-07-21T15:39:27.187Z"
   },
   {
    "duration": 32,
    "start_time": "2021-07-21T15:39:28.016Z"
   },
   {
    "duration": 331,
    "start_time": "2021-07-21T15:39:28.064Z"
   },
   {
    "duration": 11720,
    "start_time": "2021-07-21T15:39:28.398Z"
   },
   {
    "duration": 5967,
    "start_time": "2021-07-21T15:39:40.121Z"
   },
   {
    "duration": 25870,
    "start_time": "2021-07-21T15:39:46.092Z"
   },
   {
    "duration": 38003,
    "start_time": "2021-07-21T15:40:11.964Z"
   },
   {
    "duration": 158,
    "start_time": "2021-07-21T15:40:49.971Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-21T15:40:50.131Z"
   },
   {
    "duration": 25,
    "start_time": "2021-07-21T15:40:50.138Z"
   },
   {
    "duration": 77967,
    "start_time": "2021-07-21T15:40:50.165Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-21T15:42:08.135Z"
   },
   {
    "duration": 21,
    "start_time": "2021-07-21T15:42:08.142Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-21T15:42:08.166Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-21T15:42:19.799Z"
   },
   {
    "duration": 692565,
    "start_time": "2021-07-21T15:43:23.370Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-21T15:55:52.398Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-21T15:57:35.476Z"
   },
   {
    "duration": 15040,
    "start_time": "2021-07-21T15:58:52.411Z"
   },
   {
    "duration": 15141,
    "start_time": "2021-07-21T15:59:39.231Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-21T18:13:42.784Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-21T18:15:00.279Z"
   },
   {
    "duration": 2049,
    "start_time": "2021-07-21T18:59:37.950Z"
   },
   {
    "duration": 803,
    "start_time": "2021-07-21T18:59:40.002Z"
   },
   {
    "duration": 33,
    "start_time": "2021-07-21T18:59:40.808Z"
   },
   {
    "duration": 323,
    "start_time": "2021-07-21T18:59:40.862Z"
   },
   {
    "duration": 11683,
    "start_time": "2021-07-21T18:59:41.188Z"
   },
   {
    "duration": 6025,
    "start_time": "2021-07-21T18:59:52.874Z"
   },
   {
    "duration": 27178,
    "start_time": "2021-07-21T18:59:58.901Z"
   },
   {
    "duration": 37999,
    "start_time": "2021-07-21T19:00:26.082Z"
   },
   {
    "duration": 163,
    "start_time": "2021-07-21T19:01:04.084Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-21T19:01:04.250Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-21T19:01:04.264Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-21T19:01:04.273Z"
   },
   {
    "duration": -2585,
    "start_time": "2021-07-21T19:01:06.870Z"
   },
   {
    "duration": -2593,
    "start_time": "2021-07-21T19:01:06.880Z"
   },
   {
    "duration": -2594,
    "start_time": "2021-07-21T19:01:06.883Z"
   },
   {
    "duration": -2594,
    "start_time": "2021-07-21T19:01:06.884Z"
   },
   {
    "duration": -2603,
    "start_time": "2021-07-21T19:01:06.895Z"
   },
   {
    "duration": -2603,
    "start_time": "2021-07-21T19:01:06.897Z"
   },
   {
    "duration": -2615,
    "start_time": "2021-07-21T19:01:06.912Z"
   },
   {
    "duration": -2616,
    "start_time": "2021-07-21T19:01:06.914Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-21T19:09:35.598Z"
   },
   {
    "duration": 82272,
    "start_time": "2021-07-21T19:09:44.523Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-21T19:11:06.798Z"
   },
   {
    "duration": 15,
    "start_time": "2021-07-21T19:11:06.806Z"
   },
   {
    "duration": 732104,
    "start_time": "2021-07-21T19:11:06.825Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-21T19:23:18.932Z"
   },
   {
    "duration": 25,
    "start_time": "2021-07-21T19:23:18.940Z"
   },
   {
    "duration": 15297,
    "start_time": "2021-07-21T19:23:18.967Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
